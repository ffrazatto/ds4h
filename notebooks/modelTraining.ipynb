{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08df0221",
   "metadata": {},
   "source": [
    "# Análise Exploratória\n",
    "\n",
    "\n",
    "## Descrição\n",
    "Neste notebook consta a análise exploratória da base de dados utilizada no projeto *Correlação de dados de imagens de RM e dados genéticos em paciente com Esclerose Lateral Amiotrófica* para a disciplina *Ciência e Visualização de Dados em Saúde* da Universidade Estadual de Campinas, Unicamp.\n",
    "\n",
    "## Bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "730e3772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "## Basic\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "## Graph\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pandas.plotting import scatter_matrix\n",
    "from seaborn_qqplot import pplot\n",
    "\n",
    "## Machine Learning\n",
    "import statsmodels.api as sm\n",
    "#from statsmodels.formula.api import ols\n",
    "from scipy import stats\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "## Metrics\n",
    "from sklearn.metrics import r2_score\n",
    "#from scipy.stats import shapiro\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed060621",
   "metadata": {},
   "source": [
    "## Inportação de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40e26019",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID/Labls</th>\n",
       "      <th>SUPERIOR PARIETAL GYRUS left  (gm)</th>\n",
       "      <th>CINGULATE GYRUS left  (gm)</th>\n",
       "      <th>SUPERIOR FRONTAL GYRUS left (gm)</th>\n",
       "      <th>MIDDLE FRONTAL GYRUS left (gm)</th>\n",
       "      <th>INFERIOR FRONTAL GYRUS left (gm)</th>\n",
       "      <th>PRECENTRAL GYRUS left (gm)</th>\n",
       "      <th>POSTCENTRAL GYRUS left (gm)</th>\n",
       "      <th>ANGULAR GYRUS left (gm)</th>\n",
       "      <th>PRE-CUNEUS left (gm)</th>\n",
       "      <th>...</th>\n",
       "      <th>SLF-tLeft</th>\n",
       "      <th>SLFF-tRight</th>\n",
       "      <th>ICP-cerebellumLeft</th>\n",
       "      <th>ICP-cerebellumRight</th>\n",
       "      <th>CerebellumBranch-ALeft</th>\n",
       "      <th>CerebellumBranch-ARight</th>\n",
       "      <th>CerebellumBranch-BLeft</th>\n",
       "      <th>CerebellumBranch-BRight</th>\n",
       "      <th>CSF</th>\n",
       "      <th>Unused</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>c9o_02</td>\n",
       "      <td>12362</td>\n",
       "      <td>7084</td>\n",
       "      <td>16584</td>\n",
       "      <td>11484</td>\n",
       "      <td>13216</td>\n",
       "      <td>17806</td>\n",
       "      <td>8200</td>\n",
       "      <td>3140</td>\n",
       "      <td>1820</td>\n",
       "      <td>...</td>\n",
       "      <td>3888</td>\n",
       "      <td>2056</td>\n",
       "      <td>470</td>\n",
       "      <td>472</td>\n",
       "      <td>2828</td>\n",
       "      <td>2916</td>\n",
       "      <td>264</td>\n",
       "      <td>370</td>\n",
       "      <td>319946</td>\n",
       "      <td>94.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c9o_03</td>\n",
       "      <td>7348</td>\n",
       "      <td>4466</td>\n",
       "      <td>10238</td>\n",
       "      <td>6452</td>\n",
       "      <td>7454</td>\n",
       "      <td>9370</td>\n",
       "      <td>4710</td>\n",
       "      <td>2136</td>\n",
       "      <td>1066</td>\n",
       "      <td>...</td>\n",
       "      <td>2822</td>\n",
       "      <td>1392</td>\n",
       "      <td>260</td>\n",
       "      <td>296</td>\n",
       "      <td>2082</td>\n",
       "      <td>1766</td>\n",
       "      <td>422</td>\n",
       "      <td>420</td>\n",
       "      <td>230842</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c9o_04</td>\n",
       "      <td>9602</td>\n",
       "      <td>7164</td>\n",
       "      <td>14782</td>\n",
       "      <td>11700</td>\n",
       "      <td>7882</td>\n",
       "      <td>13954</td>\n",
       "      <td>5848</td>\n",
       "      <td>2262</td>\n",
       "      <td>810</td>\n",
       "      <td>...</td>\n",
       "      <td>4228</td>\n",
       "      <td>1754</td>\n",
       "      <td>216</td>\n",
       "      <td>326</td>\n",
       "      <td>2382</td>\n",
       "      <td>2712</td>\n",
       "      <td>398</td>\n",
       "      <td>474</td>\n",
       "      <td>262602</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>c9o_05</td>\n",
       "      <td>9284</td>\n",
       "      <td>7274</td>\n",
       "      <td>13514</td>\n",
       "      <td>8108</td>\n",
       "      <td>9264</td>\n",
       "      <td>11830</td>\n",
       "      <td>6120</td>\n",
       "      <td>4064</td>\n",
       "      <td>1672</td>\n",
       "      <td>...</td>\n",
       "      <td>3732</td>\n",
       "      <td>1818</td>\n",
       "      <td>256</td>\n",
       "      <td>316</td>\n",
       "      <td>2292</td>\n",
       "      <td>2118</td>\n",
       "      <td>374</td>\n",
       "      <td>320</td>\n",
       "      <td>226770</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>c9o_06</td>\n",
       "      <td>8294</td>\n",
       "      <td>6598</td>\n",
       "      <td>10790</td>\n",
       "      <td>9498</td>\n",
       "      <td>7964</td>\n",
       "      <td>10112</td>\n",
       "      <td>5232</td>\n",
       "      <td>2158</td>\n",
       "      <td>1196</td>\n",
       "      <td>...</td>\n",
       "      <td>2306</td>\n",
       "      <td>1776</td>\n",
       "      <td>262</td>\n",
       "      <td>224</td>\n",
       "      <td>2006</td>\n",
       "      <td>1812</td>\n",
       "      <td>240</td>\n",
       "      <td>286</td>\n",
       "      <td>212792</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 170 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID/Labls  SUPERIOR PARIETAL GYRUS left  (gm)  CINGULATE GYRUS left  (gm)  \\\n",
       "0   c9o_02                               12362                        7084   \n",
       "1   c9o_03                                7348                        4466   \n",
       "2   c9o_04                                9602                        7164   \n",
       "3   c9o_05                                9284                        7274   \n",
       "4   c9o_06                                8294                        6598   \n",
       "\n",
       "   SUPERIOR FRONTAL GYRUS left (gm)  MIDDLE FRONTAL GYRUS left (gm)  \\\n",
       "0                             16584                           11484   \n",
       "1                             10238                            6452   \n",
       "2                             14782                           11700   \n",
       "3                             13514                            8108   \n",
       "4                             10790                            9498   \n",
       "\n",
       "   INFERIOR FRONTAL GYRUS left (gm)  PRECENTRAL GYRUS left (gm)  \\\n",
       "0                             13216                       17806   \n",
       "1                              7454                        9370   \n",
       "2                              7882                       13954   \n",
       "3                              9264                       11830   \n",
       "4                              7964                       10112   \n",
       "\n",
       "   POSTCENTRAL GYRUS left (gm)  ANGULAR GYRUS left (gm)  PRE-CUNEUS left (gm)  \\\n",
       "0                         8200                     3140                  1820   \n",
       "1                         4710                     2136                  1066   \n",
       "2                         5848                     2262                   810   \n",
       "3                         6120                     4064                  1672   \n",
       "4                         5232                     2158                  1196   \n",
       "\n",
       "   ...  SLF-tLeft  SLFF-tRight  ICP-cerebellumLeft  ICP-cerebellumRight  \\\n",
       "0  ...       3888         2056                 470                  472   \n",
       "1  ...       2822         1392                 260                  296   \n",
       "2  ...       4228         1754                 216                  326   \n",
       "3  ...       3732         1818                 256                  316   \n",
       "4  ...       2306         1776                 262                  224   \n",
       "\n",
       "   CerebellumBranch-ALeft  CerebellumBranch-ARight  CerebellumBranch-BLeft  \\\n",
       "0                    2828                     2916                     264   \n",
       "1                    2082                     1766                     422   \n",
       "2                    2382                     2712                     398   \n",
       "3                    2292                     2118                     374   \n",
       "4                    2006                     1812                     240   \n",
       "\n",
       "   CerebellumBranch-BRight     CSF  Unused  \n",
       "0                      370  319946    94.0  \n",
       "1                      420  230842     NaN  \n",
       "2                      474  262602    40.0  \n",
       "3                      320  226770     4.0  \n",
       "4                      286  212792     2.0  \n",
       "\n",
       "[5 rows x 170 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import data\n",
    "## Path to file\n",
    "pathDTI = \"../data/raw/DTI_MultAtlas.xlsx\"\n",
    "pathT1 = \"../data/raw/freesurfer_stats_REGIONS_T1_ANALYSIS.xlsx\"\n",
    "\n",
    "## Sheets names\n",
    "### DTI\n",
    "faPath = 'FA'\n",
    "l1Path = 'l1'\n",
    "l2Path = 'l2'\n",
    "l3Path = 'l3'\n",
    "vlPath = 'volumeLabels'\n",
    "\n",
    "### T1 sheets\n",
    "volumePath = 'Volume';\n",
    "gyriSulciLHPath = 'Gyri+Sulci LH';\n",
    "gyriSulciRHPath = 'Gyri+Sulci RH';\n",
    "\n",
    "## Read each excel sheet\n",
    "### DTI data\n",
    "faDataRaw = pd.read_excel(pathDTI, sheet_name = faPath)\n",
    "l1DataRaw = pd.read_excel(pathDTI, sheet_name = l1Path)\n",
    "l2DataRaw = pd.read_excel(pathDTI, sheet_name = l2Path)\n",
    "l3DataRaw = pd.read_excel(pathDTI, sheet_name = l3Path)\n",
    "vlDataRaw = pd.read_excel(pathDTI, sheet_name = vlPath)\n",
    "\n",
    "### T1 data\n",
    "volumeDataRaw = pd.read_excel(pathT1, sheet_name = volumePath, skiprows=[1])\n",
    "gyriSulciLHDataRaw = pd.read_excel(pathT1, sheet_name = gyriSulciLHPath, skiprows = [1]);\n",
    "gyriSulciRHDataRaw = pd.read_excel(pathT1, sheet_name = gyriSulciRHPath, skiprows = [1]);\n",
    "\n",
    "vlDataRaw.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cf2423",
   "metadata": {},
   "source": [
    "## Sumário dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be22f591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: FA\n",
      "ID/Labls                               object\n",
      "SUPERIOR PARIETAL GYRUS left  (gm)    float64\n",
      "CINGULATE GYRUS left  (gm)            float64\n",
      "SUPERIOR FRONTAL GYRUS left (gm)      float64\n",
      "MIDDLE FRONTAL GYRUS left (gm)        float64\n",
      "                                       ...   \n",
      "CerebellumBranch-ARight               float64\n",
      "CerebellumBranch-BLeft                float64\n",
      "CerebellumBranch-BRight               float64\n",
      "CSF                                   float64\n",
      "Unused                                float64\n",
      "Length: 170, dtype: object\n",
      "\n",
      "\n",
      "Dataset: L1\n",
      "ID/Labls                               object\n",
      "SUPERIOR PARIETAL GYRUS left  (gm)    float64\n",
      "CINGULATE GYRUS left  (gm)            float64\n",
      "SUPERIOR FRONTAL GYRUS left (gm)      float64\n",
      "MIDDLE FRONTAL GYRUS left (gm)        float64\n",
      "                                       ...   \n",
      "CerebellumBranch-ARight               float64\n",
      "CerebellumBranch-BLeft                float64\n",
      "CerebellumBranch-BRight               float64\n",
      "CSF                                   float64\n",
      "Unused                                float64\n",
      "Length: 170, dtype: object\n",
      "\n",
      "\n",
      "Dataset: L2\n",
      "ID/Labls                               object\n",
      "SUPERIOR PARIETAL GYRUS left  (gm)    float64\n",
      "CINGULATE GYRUS left  (gm)            float64\n",
      "SUPERIOR FRONTAL GYRUS left (gm)      float64\n",
      "MIDDLE FRONTAL GYRUS left (gm)        float64\n",
      "                                       ...   \n",
      "CerebellumBranch-ARight               float64\n",
      "CerebellumBranch-BLeft                float64\n",
      "CerebellumBranch-BRight               float64\n",
      "CSF                                   float64\n",
      "Unused                                float64\n",
      "Length: 170, dtype: object\n",
      "\n",
      "\n",
      "Dataset: L3\n",
      "ID/Labls                               object\n",
      "SUPERIOR PARIETAL GYRUS left  (gm)    float64\n",
      "CINGULATE GYRUS left  (gm)            float64\n",
      "SUPERIOR FRONTAL GYRUS left (gm)      float64\n",
      "MIDDLE FRONTAL GYRUS left (gm)        float64\n",
      "                                       ...   \n",
      "CerebellumBranch-ARight               float64\n",
      "CerebellumBranch-BLeft                float64\n",
      "CerebellumBranch-BRight               float64\n",
      "CSF                                   float64\n",
      "Unused                                float64\n",
      "Length: 170, dtype: object\n",
      "\n",
      "\n",
      "Dataset: Volume Labels\n",
      "ID/Labls                               object\n",
      "SUPERIOR PARIETAL GYRUS left  (gm)      int64\n",
      "CINGULATE GYRUS left  (gm)              int64\n",
      "SUPERIOR FRONTAL GYRUS left (gm)        int64\n",
      "MIDDLE FRONTAL GYRUS left (gm)          int64\n",
      "                                       ...   \n",
      "CerebellumBranch-ARight                 int64\n",
      "CerebellumBranch-BLeft                  int64\n",
      "CerebellumBranch-BRight                 int64\n",
      "CSF                                     int64\n",
      "Unused                                float64\n",
      "Length: 170, dtype: object\n",
      "Dataset: Volume\n",
      "Unnamed: 0                object\n",
      "Unnamed: 1                object\n",
      "Unnamed: 2                object\n",
      "#eTIV                    float64\n",
      "Brain-Stem               float64\n",
      "CC_Anterior              float64\n",
      "CC_Central               float64\n",
      "CC_Mid_Anterior          float64\n",
      "CC_Mid_Posterior         float64\n",
      "CC_Posterior             float64\n",
      "Left-Accumbens-area      float64\n",
      "Left-Amygdala            float64\n",
      "Left-Caudate             float64\n",
      "Left-Hippocampus         float64\n",
      "Left-Pallidum            float64\n",
      "Left-Putamen             float64\n",
      "Left-Thalamus-Proper     float64\n",
      "Left-VentralDC           float64\n",
      "Left-choroid-plexus      float64\n",
      "Right-Accumbens-area     float64\n",
      "Right-Amygdala           float64\n",
      "Right-Caudate            float64\n",
      "Right-Hippocampus        float64\n",
      "Right-Pallidum           float64\n",
      "Right-Putamen            float64\n",
      "Right-Thalamus-Proper    float64\n",
      "Right-VentralDC          float64\n",
      "Right-choroid-plexus     float64\n",
      "dtype: object\n",
      "Dataset: gyriSulciLH\n",
      "Unnamed: 0                object\n",
      "Unnamed: 1                object\n",
      "Unnamed: 2                object\n",
      "G&S_cingul-Ant           float64\n",
      "G&S_cingul-Mid-Ant       float64\n",
      "                          ...   \n",
      "S_suborbital             float64\n",
      "S_subparietal            float64\n",
      "S_temporal_inf           float64\n",
      "S_temporal_sup           float64\n",
      "S_temporal_transverse    float64\n",
      "Length: 77, dtype: object\n",
      "Dataset: gyriSulciRH\n",
      "Unnamed: 0                object\n",
      "Unnamed: 1                object\n",
      "Unnamed: 2                object\n",
      "G&S_cingul-Ant           float64\n",
      "G&S_cingul-Mid-Ant       float64\n",
      "                          ...   \n",
      "S_suborbital             float64\n",
      "S_subparietal            float64\n",
      "S_temporal_inf           float64\n",
      "S_temporal_sup           float64\n",
      "S_temporal_transverse    float64\n",
      "Length: 77, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Data Summary 2\n",
    "## Data types\n",
    "print(\"Dataset: FA\")\n",
    "print(faDataRaw.dtypes)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Dataset: L1\")\n",
    "print(l1DataRaw.dtypes)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Dataset: L2\")\n",
    "print(l2DataRaw.dtypes)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Dataset: L3\")\n",
    "print(l3DataRaw.dtypes)\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Dataset: Volume Labels\")\n",
    "print(vlDataRaw.dtypes)\n",
    "\n",
    "print(\"Dataset: Volume\")\n",
    "print(volumeDataRaw.dtypes)\n",
    "\n",
    "print(\"Dataset: gyriSulciLH\")\n",
    "print(gyriSulciLHDataRaw.dtypes)\n",
    "\n",
    "print(\"Dataset: gyriSulciRH\")\n",
    "print(gyriSulciRHDataRaw.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b5f82f",
   "metadata": {},
   "source": [
    "## Dimensões e Dados Faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7334c829",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataShape(dataset):\n",
    "    rows = dataset.shape[0]\n",
    "    columns = dataset.shape[1]\n",
    "    missing = dataset.isnull().sum().sum()\n",
    "    \n",
    "    return rows, columns, missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9107cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "faRows, faColumns, faMissing = dataShape(faDataRaw)\n",
    "l1Rows, l1Columns, l1Missing = dataShape(l1DataRaw)\n",
    "l2Rows, l2Columns, l2Missing = dataShape(l2DataRaw)\n",
    "l3Rows, l3Columns, l3Missing = dataShape(l3DataRaw)\n",
    "vlRows, vlColumns, vlMissing = dataShape(vlDataRaw)\n",
    "volRows, volColumns, volMissing = dataShape(volumeDataRaw)\n",
    "gslhRows, gslhColumns, gslhMissing = dataShape(gyriSulciLHDataRaw)\n",
    "gsrhRows, gsrhColumns, gsrhMissing = dataShape(gyriSulciRHDataRaw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a199fe1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table 1: DTI Data Summary\n",
      "           Data  Rows  Columns  Missing\n",
      "0            FA    87      170      322\n",
      "1            L1    87      170      322\n",
      "2            L2    87      170      322\n",
      "3            L3    87      170      322\n",
      "4  volumeLabels    87      170      322\n",
      "\n",
      "\n",
      "Table 2: T1 Data Summary\n",
      "     Data  Rows  Columns  Missing\n",
      "0  volume    91       28        0\n",
      "1   GS_LH    91       77        0\n",
      "2   GS_RH    91       77        0\n"
     ]
    }
   ],
   "source": [
    "# Summary\n",
    "dtiDataSummary = pd.DataFrame({'Data' : ['FA', 'L1',  'L2', 'L3', 'volumeLabels'],\n",
    "                              'Rows' : [faRows, l1Rows, l2Rows, l3Rows, vlRows], \n",
    "                              'Columns' : [faColumns, l1Columns, l2Columns, l3Columns, vlColumns],\n",
    "                              'Missing' : [faMissing, l1Missing, l2Missing, l3Missing, vlMissing]});\n",
    "\n",
    "t1DataSummary = pd.DataFrame({'Data' : ['volume', 'GS_LH',  'GS_RH'],\n",
    "                              'Rows' : [volRows, gslhRows, gsrhRows], \n",
    "                              'Columns' : [volColumns, gslhColumns, gsrhColumns],\n",
    "                              'Missing' : [volMissing, gslhMissing, gsrhMissing]});\n",
    "\n",
    "\n",
    "print(\"Table 1: DTI Data Summary\")\n",
    "print(dtiDataSummary)\n",
    "print('\\n')\n",
    "print(\"Table 2: T1 Data Summary\")\n",
    "print(t1DataSummary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "026a5857",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMissing(dataset):\n",
    "    missingColumns = []\n",
    "    \n",
    "    print('Column\\tMissing Values')\n",
    "    for i in range(0, dataset.shape[1]):\n",
    "        missing = dataset.iloc[:,i].isnull().sum()\n",
    "        if(missing > 0):\n",
    "            missingColumns.append(dataset.columns[i])\n",
    "            print('%s\\t%d'%(dataset.columns[i], missing))\n",
    "            \n",
    "    return missingColumns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "97a7846b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: FA\n",
      "\n",
      "Column\tMissing Values\n",
      "SuperiorFronto-occipitalFasciculusLeft\t6\n",
      "UncinateFasciculusLeft\t1\n",
      "Red Nucleus left\t21\n",
      "SuperiorFronto-occipitalFasciculusRight\t1\n",
      "Red Nucleus right\t17\n",
      "GLOBUS PALLIDUS right\t1\n",
      "Mammillary body right\t75\n",
      "Mammillary body left\t21\n",
      "Hypothalamus E left\t76\n",
      "Hypothalamus E right\t86\n",
      "LVL_occipitalRight\t12\n",
      "Unused\t5\n",
      "\n",
      "=======================\n",
      "\n",
      "Dataset: L1\n",
      "\n",
      "Column\tMissing Values\n",
      "SuperiorFronto-occipitalFasciculusLeft\t6\n",
      "UncinateFasciculusLeft\t1\n",
      "Red Nucleus left\t21\n",
      "SuperiorFronto-occipitalFasciculusRight\t1\n",
      "Red Nucleus right\t17\n",
      "GLOBUS PALLIDUS right\t1\n",
      "Mammillary body right\t75\n",
      "Mammillary body left\t21\n",
      "Hypothalamus E left\t76\n",
      "Hypothalamus E right\t86\n",
      "LVL_occipitalRight\t12\n",
      "Unused\t5\n",
      "\n",
      "=======================\n",
      "\n",
      "Dataset: L2\n",
      "\n",
      "Column\tMissing Values\n",
      "SuperiorFronto-occipitalFasciculusLeft\t6\n",
      "UncinateFasciculusLeft\t1\n",
      "Red Nucleus left\t21\n",
      "SuperiorFronto-occipitalFasciculusRight\t1\n",
      "Red Nucleus right\t17\n",
      "GLOBUS PALLIDUS right\t1\n",
      "Mammillary body right\t75\n",
      "Mammillary body left\t21\n",
      "Hypothalamus E left\t76\n",
      "Hypothalamus E right\t86\n",
      "LVL_occipitalRight\t12\n",
      "Unused\t5\n",
      "\n",
      "=======================\n",
      "\n",
      "Dataset: L3\n",
      "\n",
      "Column\tMissing Values\n",
      "SuperiorFronto-occipitalFasciculusLeft\t6\n",
      "UncinateFasciculusLeft\t1\n",
      "Red Nucleus left\t21\n",
      "SuperiorFronto-occipitalFasciculusRight\t1\n",
      "Red Nucleus right\t17\n",
      "GLOBUS PALLIDUS right\t1\n",
      "Mammillary body right\t75\n",
      "Mammillary body left\t21\n",
      "Hypothalamus E left\t76\n",
      "Hypothalamus E right\t86\n",
      "LVL_occipitalRight\t12\n",
      "Unused\t5\n",
      "\n",
      "=======================\n",
      "\n",
      "Dataset: Volume Labels\n",
      "\n",
      "Column\tMissing Values\n",
      "SuperiorFronto-occipitalFasciculusLeft\t6\n",
      "UncinateFasciculusLeft\t1\n",
      "Red Nucleus left\t21\n",
      "SuperiorFronto-occipitalFasciculusRight\t1\n",
      "Red Nucleus right\t17\n",
      "GLOBUS PALLIDUS right\t1\n",
      "Mammillary body right\t75\n",
      "Mammillary body left\t21\n",
      "Hypothalamus E left\t76\n",
      "Hypothalamus E right\t86\n",
      "LVL_occipitalRight\t12\n",
      "Unused\t5\n"
     ]
    }
   ],
   "source": [
    "print('Dataset: FA\\n')\n",
    "faMissingColumns = getMissing(faDataRaw)\n",
    "print('\\n=======================\\n')\n",
    "print('Dataset: L1\\n')\n",
    "l1MissingColumns = getMissing(l1DataRaw)\n",
    "print('\\n=======================\\n')\n",
    "print('Dataset: L2\\n')\n",
    "l2MissingColumns = getMissing(l2DataRaw)\n",
    "print('\\n=======================\\n')\n",
    "print('Dataset: L3\\n')\n",
    "l3MissingColumns = getMissing(l3DataRaw)\n",
    "print('\\n=======================\\n')\n",
    "print('Dataset: Volume Labels\\n')\n",
    "vlMissingColumns = getMissing(vlDataRaw)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9b7c36",
   "metadata": {},
   "source": [
    "## Limpeza\n",
    "\n",
    "1. Backup dos dados\n",
    "2. Excluir colunas irrelevantes (\"Unnamed 1\" e \"Unnamed 2\")\n",
    "3. Renomear primeira coluna de \"Unnamed 0\" para \"subject\"\n",
    "4. Criação da coluna \"als\", discriminando pacientes com e sem ELA\n",
    "5. Criaçào da coluna \"group\", discriminando pacientes do grupo de controle e diferentes tipos \n",
    "de ELA (ELAs, C9orf72 e VAPB)\n",
    "6. União dos 3 dataset em um único dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "616ec192",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataClean(dataset, missingColumns, suffix, dataType):\n",
    "    # Backup Data\n",
    "    data = dataset.copy(); \n",
    "    \n",
    "    if(dataType == 'dti'):\n",
    "        # Drop all columns with missing values\n",
    "        data.drop(missingColumns, axis = 1, inplace = True);\n",
    "    \n",
    "        # Change first column name\n",
    "        data.rename(columns = {'ID/Labls' : 'subject'}, inplace = True);\n",
    "    \n",
    "        # Add sufix to each feature name\n",
    "        for i in range(1, data.shape[1]):\n",
    "            colName = data.columns[i] + '_' + suffix\n",
    "            data.rename(columns = {data.columns[i] : colName}, inplace = True)\n",
    "    \n",
    "    if(dataType == 't1'):\n",
    "        ## Drop unnamed columns\n",
    "        data.drop([\"Unnamed: 1\", 'Unnamed: 2'], axis = 1, inplace = True);\n",
    "        ## Rename first column\n",
    "        data.rename(columns = {'Unnamed: 0' : 'subject'}, inplace = True);\n",
    "    \n",
    "    # Create two new features    \n",
    "    ## New column: ALS\n",
    "    ### Map Values\n",
    "    #### Legend\n",
    "    #### 0 = control\n",
    "    #### 1 =  ALS confirmed\n",
    "    data['als'] = 1\n",
    "    data.loc[data['subject'].str.startswith('ctl'), 'als'] = 0\n",
    "   \n",
    "    ## New column: Group\n",
    "    ### Map Values\n",
    "    #### Legend\n",
    "    #### 0 = control\n",
    "    #### 1 = sporadic ALS\n",
    "    #### 2 = c9o ALS\n",
    "    #### 3 = vapb ALS\n",
    "    data['group'] = 0\n",
    "    data.loc[data['subject'].str.startswith('sals'), 'group'] = 1\n",
    "    data.loc[data['subject'].str.startswith('c9o'), 'group'] = 2\n",
    "    data.loc[data['subject'].str.startswith('vap'), 'group'] = 3\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1abea123",
   "metadata": {},
   "outputs": [],
   "source": [
    "faData = dataClean(faDataRaw, faMissingColumns, 'fa', 'dti')\n",
    "l1Data = dataClean(l1DataRaw, l1MissingColumns, 'l1', 'dti')\n",
    "l2Data = dataClean(l2DataRaw, l2MissingColumns, 'l2', 'dti')\n",
    "l3Data = dataClean(l3DataRaw, l3MissingColumns, 'l3', 'dti')\n",
    "vlData = dataClean(vlDataRaw, vlMissingColumns, 'vl', 'dti')\n",
    "volData = dataClean(volumeDataRaw, [], 'vol', 't1')\n",
    "gslhData = dataClean(gyriSulciLHDataRaw, [], 'gslh', 't1')\n",
    "gsrhData = dataClean(gyriSulciRHDataRaw, [], 'gsrh', 't1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fdc1ddeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "newMetricsMD = l1Data.copy()\n",
    "newMetricsRD = l1Data.copy()\n",
    "\n",
    "for i in range(1, newMetricsMD.shape[1]):\n",
    "    if(newMetricsMD.columns[i] != 'als' and newMetricsMD.columns[i] != 'group'):\n",
    "        colName = newMetricsMD.columns[i][0:-3] + '_md'\n",
    "        newMetricsMD.rename(columns = {newMetricsMD.columns[i] : colName}, inplace = True)\n",
    "        \n",
    "        colName = newMetricsRD.columns[i][0:-3] + '_rd'     \n",
    "        newMetricsRD.rename(columns = {newMetricsRD.columns[i] : colName}, inplace = True)\n",
    "\n",
    "\n",
    "for i in range(0, l1Data.shape[0]):\n",
    "    for j in range(1, l1Data.shape[1]):\n",
    "        newMetricsMD.iloc[i, j] = (l1Data.iloc[i, j] + \n",
    "                                   l2Data.iloc[i, j] + \n",
    "                                   l3Data.iloc[i, j])/3\n",
    "        \n",
    "        newMetricsRD.iloc[i, j] = (l2Data.iloc[i, j] + \n",
    "                                   l3Data.iloc[i, j])/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd9f1c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge DTI all data into one dataframe\n",
    "dtiData = faData.copy()\n",
    "dtiData = dtiData.merge(l1Data, how = 'inner', on = ['subject', 'als', 'group'])\n",
    "dtiData = dtiData.merge(newMetricsMD, how = 'inner', on = ['subject', 'als', 'group'])\n",
    "dtiData = dtiData.merge(newMetricsRD, how = 'inner', on = ['subject', 'als', 'group'])\n",
    "dtiData = dtiData.merge(vlData, how = 'inner', on = ['subject', 'als', 'group'])\n",
    "\n",
    "# Merge T1 all data into one dataframe\n",
    "t1Data = volData.copy()\n",
    "t1Data = t1Data.merge(gslhData, how = 'inner', on = ['subject', 'als', 'group'])\n",
    "t1Data = t1Data.merge(gsrhData, how = 'inner', on = ['subject', 'als', 'group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "495e60ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>subject</th>\n",
       "      <th>#eTIV</th>\n",
       "      <th>Brain-Stem</th>\n",
       "      <th>CC_Anterior</th>\n",
       "      <th>CC_Central</th>\n",
       "      <th>CC_Mid_Anterior</th>\n",
       "      <th>CC_Mid_Posterior</th>\n",
       "      <th>CC_Posterior</th>\n",
       "      <th>Left-Accumbens-area</th>\n",
       "      <th>...</th>\n",
       "      <th>III and IV ventricle_vl</th>\n",
       "      <th>SLF-tLeft_vl</th>\n",
       "      <th>SLFF-tRight_vl</th>\n",
       "      <th>ICP-cerebellumLeft_vl</th>\n",
       "      <th>ICP-cerebellumRight_vl</th>\n",
       "      <th>CerebellumBranch-ALeft_vl</th>\n",
       "      <th>CerebellumBranch-ARight_vl</th>\n",
       "      <th>CerebellumBranch-BLeft_vl</th>\n",
       "      <th>CerebellumBranch-BRight_vl</th>\n",
       "      <th>CSF_vl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>c9o_02</td>\n",
       "      <td>1.913195e+06</td>\n",
       "      <td>28663.3</td>\n",
       "      <td>1537.6</td>\n",
       "      <td>621.4</td>\n",
       "      <td>617.7</td>\n",
       "      <td>653.4</td>\n",
       "      <td>1164.1</td>\n",
       "      <td>538.5</td>\n",
       "      <td>...</td>\n",
       "      <td>6892</td>\n",
       "      <td>3888</td>\n",
       "      <td>2056</td>\n",
       "      <td>470</td>\n",
       "      <td>472</td>\n",
       "      <td>2828</td>\n",
       "      <td>2916</td>\n",
       "      <td>264</td>\n",
       "      <td>370</td>\n",
       "      <td>319946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>c9o_03</td>\n",
       "      <td>1.156390e+06</td>\n",
       "      <td>17449.3</td>\n",
       "      <td>790.4</td>\n",
       "      <td>593.5</td>\n",
       "      <td>562.1</td>\n",
       "      <td>461.4</td>\n",
       "      <td>953.7</td>\n",
       "      <td>394.1</td>\n",
       "      <td>...</td>\n",
       "      <td>4226</td>\n",
       "      <td>2822</td>\n",
       "      <td>1392</td>\n",
       "      <td>260</td>\n",
       "      <td>296</td>\n",
       "      <td>2082</td>\n",
       "      <td>1766</td>\n",
       "      <td>422</td>\n",
       "      <td>420</td>\n",
       "      <td>230842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>c9o_04</td>\n",
       "      <td>1.841581e+06</td>\n",
       "      <td>22053.6</td>\n",
       "      <td>1559.7</td>\n",
       "      <td>509.1</td>\n",
       "      <td>506.2</td>\n",
       "      <td>438.4</td>\n",
       "      <td>1264.5</td>\n",
       "      <td>455.6</td>\n",
       "      <td>...</td>\n",
       "      <td>8470</td>\n",
       "      <td>4228</td>\n",
       "      <td>1754</td>\n",
       "      <td>216</td>\n",
       "      <td>326</td>\n",
       "      <td>2382</td>\n",
       "      <td>2712</td>\n",
       "      <td>398</td>\n",
       "      <td>474</td>\n",
       "      <td>262602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>c9o_05</td>\n",
       "      <td>1.406566e+06</td>\n",
       "      <td>18810.9</td>\n",
       "      <td>857.5</td>\n",
       "      <td>521.3</td>\n",
       "      <td>644.0</td>\n",
       "      <td>532.3</td>\n",
       "      <td>1006.9</td>\n",
       "      <td>467.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5952</td>\n",
       "      <td>3732</td>\n",
       "      <td>1818</td>\n",
       "      <td>256</td>\n",
       "      <td>316</td>\n",
       "      <td>2292</td>\n",
       "      <td>2118</td>\n",
       "      <td>374</td>\n",
       "      <td>320</td>\n",
       "      <td>226770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>c9o_06</td>\n",
       "      <td>1.191194e+06</td>\n",
       "      <td>20039.0</td>\n",
       "      <td>808.5</td>\n",
       "      <td>578.2</td>\n",
       "      <td>507.3</td>\n",
       "      <td>566.1</td>\n",
       "      <td>1086.1</td>\n",
       "      <td>400.6</td>\n",
       "      <td>...</td>\n",
       "      <td>5298</td>\n",
       "      <td>2306</td>\n",
       "      <td>1776</td>\n",
       "      <td>262</td>\n",
       "      <td>224</td>\n",
       "      <td>2006</td>\n",
       "      <td>1812</td>\n",
       "      <td>240</td>\n",
       "      <td>286</td>\n",
       "      <td>212792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>86</td>\n",
       "      <td>vap_23</td>\n",
       "      <td>1.322953e+06</td>\n",
       "      <td>17890.6</td>\n",
       "      <td>919.7</td>\n",
       "      <td>647.8</td>\n",
       "      <td>687.5</td>\n",
       "      <td>635.3</td>\n",
       "      <td>1119.6</td>\n",
       "      <td>470.8</td>\n",
       "      <td>...</td>\n",
       "      <td>5228</td>\n",
       "      <td>2658</td>\n",
       "      <td>1338</td>\n",
       "      <td>246</td>\n",
       "      <td>284</td>\n",
       "      <td>1746</td>\n",
       "      <td>1530</td>\n",
       "      <td>212</td>\n",
       "      <td>266</td>\n",
       "      <td>262232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>87</td>\n",
       "      <td>vap_24</td>\n",
       "      <td>1.199364e+06</td>\n",
       "      <td>17381.8</td>\n",
       "      <td>846.1</td>\n",
       "      <td>482.6</td>\n",
       "      <td>604.1</td>\n",
       "      <td>509.2</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>528.7</td>\n",
       "      <td>...</td>\n",
       "      <td>7624</td>\n",
       "      <td>2678</td>\n",
       "      <td>1156</td>\n",
       "      <td>252</td>\n",
       "      <td>350</td>\n",
       "      <td>1954</td>\n",
       "      <td>2218</td>\n",
       "      <td>280</td>\n",
       "      <td>308</td>\n",
       "      <td>229296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>88</td>\n",
       "      <td>vap_25</td>\n",
       "      <td>1.468567e+06</td>\n",
       "      <td>17870.6</td>\n",
       "      <td>1043.6</td>\n",
       "      <td>503.1</td>\n",
       "      <td>805.1</td>\n",
       "      <td>672.8</td>\n",
       "      <td>1281.2</td>\n",
       "      <td>533.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7222</td>\n",
       "      <td>3382</td>\n",
       "      <td>2042</td>\n",
       "      <td>280</td>\n",
       "      <td>390</td>\n",
       "      <td>2568</td>\n",
       "      <td>2404</td>\n",
       "      <td>276</td>\n",
       "      <td>276</td>\n",
       "      <td>243586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>89</td>\n",
       "      <td>vap_26</td>\n",
       "      <td>1.548146e+06</td>\n",
       "      <td>19757.0</td>\n",
       "      <td>845.5</td>\n",
       "      <td>509.0</td>\n",
       "      <td>633.7</td>\n",
       "      <td>665.3</td>\n",
       "      <td>1135.4</td>\n",
       "      <td>513.3</td>\n",
       "      <td>...</td>\n",
       "      <td>6672</td>\n",
       "      <td>3108</td>\n",
       "      <td>2246</td>\n",
       "      <td>236</td>\n",
       "      <td>374</td>\n",
       "      <td>2550</td>\n",
       "      <td>2632</td>\n",
       "      <td>370</td>\n",
       "      <td>370</td>\n",
       "      <td>255380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>90</td>\n",
       "      <td>vap_27</td>\n",
       "      <td>1.051132e+06</td>\n",
       "      <td>20726.5</td>\n",
       "      <td>1204.3</td>\n",
       "      <td>566.8</td>\n",
       "      <td>626.1</td>\n",
       "      <td>615.2</td>\n",
       "      <td>1137.7</td>\n",
       "      <td>539.3</td>\n",
       "      <td>...</td>\n",
       "      <td>6334</td>\n",
       "      <td>2280</td>\n",
       "      <td>1476</td>\n",
       "      <td>312</td>\n",
       "      <td>358</td>\n",
       "      <td>2446</td>\n",
       "      <td>2346</td>\n",
       "      <td>294</td>\n",
       "      <td>270</td>\n",
       "      <td>219592</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>87 rows × 962 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    index subject         #eTIV  Brain-Stem  CC_Anterior  CC_Central  \\\n",
       "0       0  c9o_02  1.913195e+06     28663.3       1537.6       621.4   \n",
       "1       1  c9o_03  1.156390e+06     17449.3        790.4       593.5   \n",
       "2       2  c9o_04  1.841581e+06     22053.6       1559.7       509.1   \n",
       "3       3  c9o_05  1.406566e+06     18810.9        857.5       521.3   \n",
       "4       4  c9o_06  1.191194e+06     20039.0        808.5       578.2   \n",
       "..    ...     ...           ...         ...          ...         ...   \n",
       "82     86  vap_23  1.322953e+06     17890.6        919.7       647.8   \n",
       "83     87  vap_24  1.199364e+06     17381.8        846.1       482.6   \n",
       "84     88  vap_25  1.468567e+06     17870.6       1043.6       503.1   \n",
       "85     89  vap_26  1.548146e+06     19757.0        845.5       509.0   \n",
       "86     90  vap_27  1.051132e+06     20726.5       1204.3       566.8   \n",
       "\n",
       "    CC_Mid_Anterior  CC_Mid_Posterior  CC_Posterior  Left-Accumbens-area  ...  \\\n",
       "0             617.7             653.4        1164.1                538.5  ...   \n",
       "1             562.1             461.4         953.7                394.1  ...   \n",
       "2             506.2             438.4        1264.5                455.6  ...   \n",
       "3             644.0             532.3        1006.9                467.0  ...   \n",
       "4             507.3             566.1        1086.1                400.6  ...   \n",
       "..              ...               ...           ...                  ...  ...   \n",
       "82            687.5             635.3        1119.6                470.8  ...   \n",
       "83            604.1             509.2        1000.0                528.7  ...   \n",
       "84            805.1             672.8        1281.2                533.0  ...   \n",
       "85            633.7             665.3        1135.4                513.3  ...   \n",
       "86            626.1             615.2        1137.7                539.3  ...   \n",
       "\n",
       "    III and IV ventricle_vl  SLF-tLeft_vl  SLFF-tRight_vl  \\\n",
       "0                      6892          3888            2056   \n",
       "1                      4226          2822            1392   \n",
       "2                      8470          4228            1754   \n",
       "3                      5952          3732            1818   \n",
       "4                      5298          2306            1776   \n",
       "..                      ...           ...             ...   \n",
       "82                     5228          2658            1338   \n",
       "83                     7624          2678            1156   \n",
       "84                     7222          3382            2042   \n",
       "85                     6672          3108            2246   \n",
       "86                     6334          2280            1476   \n",
       "\n",
       "    ICP-cerebellumLeft_vl  ICP-cerebellumRight_vl  CerebellumBranch-ALeft_vl  \\\n",
       "0                     470                     472                       2828   \n",
       "1                     260                     296                       2082   \n",
       "2                     216                     326                       2382   \n",
       "3                     256                     316                       2292   \n",
       "4                     262                     224                       2006   \n",
       "..                    ...                     ...                        ...   \n",
       "82                    246                     284                       1746   \n",
       "83                    252                     350                       1954   \n",
       "84                    280                     390                       2568   \n",
       "85                    236                     374                       2550   \n",
       "86                    312                     358                       2446   \n",
       "\n",
       "    CerebellumBranch-ARight_vl  CerebellumBranch-BLeft_vl  \\\n",
       "0                         2916                        264   \n",
       "1                         1766                        422   \n",
       "2                         2712                        398   \n",
       "3                         2118                        374   \n",
       "4                         1812                        240   \n",
       "..                         ...                        ...   \n",
       "82                        1530                        212   \n",
       "83                        2218                        280   \n",
       "84                        2404                        276   \n",
       "85                        2632                        370   \n",
       "86                        2346                        294   \n",
       "\n",
       "    CerebellumBranch-BRight_vl  CSF_vl  \n",
       "0                          370  319946  \n",
       "1                          420  230842  \n",
       "2                          474  262602  \n",
       "3                          320  226770  \n",
       "4                          286  212792  \n",
       "..                         ...     ...  \n",
       "82                         266  262232  \n",
       "83                         308  229296  \n",
       "84                         276  243586  \n",
       "85                         370  255380  \n",
       "86                         270  219592  \n",
       "\n",
       "[87 rows x 962 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1Copy = t1Data.copy()\n",
    "\n",
    "found = False\n",
    "for i in range(0, t1Copy.shape[0]):\n",
    "    for j in range(0, dtiData.shape[0]):\n",
    "        if(t1Copy['subject'][i] == dtiData['subject'][j]):\n",
    "            found = True\n",
    "    \n",
    "    if(not(found)):\n",
    "        t1Copy.drop(i, inplace = True)\n",
    "        found = False\n",
    "    found = False\n",
    "t1Copy.reset_index(inplace = True)\n",
    "\n",
    "allData = t1Copy.copy()\n",
    "allData = allData.merge(dtiData, how = 'inner', on = ['subject', 'als', 'group'])\n",
    "allData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "268778ec",
   "metadata": {},
   "source": [
    "## Treinamento do Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1915bcbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import feature_selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import ShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60ad1ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Helper functions\n",
    "\n",
    "# Compute confusion matrix, sensitivity and specificity\n",
    "def results(model, x, y):\n",
    "    yPred = model.predict(x) # Model predictions\n",
    "    CM = confusion_matrix(y, yPred) # Compute confusion Matrix\n",
    "    Sens = CM[1,1]/(y == 1).sum() # Calculate Sensitivity\n",
    "    Spec = CM[0,0]/(y == 0).sum() # Calculate Specificity\n",
    "    \n",
    "    print('matriz de confusão = \\n', CM)\n",
    "    print('Sensibilidade = ', Sens)\n",
    "    print('Especificidade = ', Spec)\n",
    "    print('acc = ', np.sum(y == yPred)/yPred.size)\n",
    "    \n",
    "# Show result for the different datasets\n",
    "def showResults(model, name, x, y, xTrain, xVal, xTest, yTrain, yVal, yTest):\n",
    "    title = 'Modelo: ' + name\n",
    "    print(title)\n",
    "\n",
    "    print('Conjunto de Treino\\n')\n",
    "    results(model, xTrain, yTrain)\n",
    "    \n",
    "    print('\\nConjunto de Validação\\n')\n",
    "    results(model, xVal, yVal)\n",
    "    \n",
    "    print('\\nConjunto de Teste\\n')\n",
    "    results(model, xTest, yTest)\n",
    "    \n",
    "    #Calculate Cross Validation\n",
    "    k = 100\n",
    "    print('Cross validation (%d-Fold):'%(k))\n",
    "    cv = ShuffleSplit(n_splits = k, test_size = 0.33, random_state = 5)\n",
    "    scores = cross_val_score(model, x, y, cv=cv)\n",
    "    print('Score = ', scores.mean())\n",
    "    print('Std = ', scores.std())\n",
    "    \n",
    "def prepareData(dataset, target, zeroVariance = 0, pca = 0):\n",
    "    x = dataset.drop(['subject', 'als', 'group'], axis=1)\n",
    "    y = dataset[target]\n",
    "\n",
    "    print('Initial Dimensions: ', x.shape)\n",
    "    if(zeroVariance > 0):\n",
    "        sel = feature_selection.VarianceThreshold(threshold = zeroVariance)\n",
    "        x = sel.fit_transform(x)\n",
    "        print('Post zeroVar: ', x.shape)\n",
    "    if(pca > 0):\n",
    "        x = PCA(pca).fit_transform(x)\n",
    "        print('Post pca: ', x.shape)\n",
    "\n",
    "    xTrain, xTmp, yTrain, yTmp = train_test_split(x, y, test_size = 0.6, random_state = 5)\n",
    "    xVal, xTest, yVal, yTest = train_test_split(xTmp, yTmp, test_size = 0.5, random_state = 5)\n",
    "\n",
    "    xTrain = sm.add_constant(xTrain)\n",
    "    xVal = sm.add_constant(xVal)\n",
    "    xTest = sm.add_constant(xTest)\n",
    "\n",
    "    return x, y, xTrain, yTrain, xVal, yVal, xTest, yTest    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87d63209",
   "metadata": {},
   "source": [
    "### Classificador ELA/Saudavel\n",
    "#### Dados: Apenas DTI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8f4403d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Dimensions:  (87, 785)\n",
      "Post zeroVar:  (87, 157)\n",
      "Post pca:  (87, 18)\n"
     ]
    }
   ],
   "source": [
    "filteredData = dtiData\n",
    "\n",
    "x, y, xTrain, yTrain, xVal, yVal, xTest, yTest = prepareData(filteredData, 'als', 0.1, 0.99)\n",
    "\n",
    "clfAlsLR = make_pipeline(StandardScaler(), LogisticRegression(penalty='l2', max_iter = 5000))\n",
    "clfAlsSVM = make_pipeline(StandardScaler(), svm.SVC(gamma='auto', kernel='rbf'))\n",
    "clfAlsRF = make_pipeline(StandardScaler(), RandomForestClassifier())\n",
    "\n",
    "clfAlsLR.fit(xTrain, yTrain);\n",
    "clfAlsSVM.fit(xTrain, yTrain);\n",
    "clfAlsRF.fit(xTrain, yTrain);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f333b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo: Logistic Regression\n",
      "Conjunto de Treino\n",
      "\n",
      "matriz de confusão = \n",
      " [[ 5  1]\n",
      " [ 1 27]]\n",
      "Sensibilidade =  0.9642857142857143\n",
      "Especificidade =  0.8333333333333334\n",
      "acc =  0.9411764705882353\n",
      "\n",
      "Conjunto de Validação\n",
      "\n",
      "matriz de confusão = \n",
      " [[ 1  6]\n",
      " [ 1 18]]\n",
      "Sensibilidade =  0.9473684210526315\n",
      "Especificidade =  0.14285714285714285\n",
      "acc =  0.7307692307692307\n",
      "\n",
      "Conjunto de Teste\n",
      "\n",
      "matriz de confusão = \n",
      " [[ 3  4]\n",
      " [ 3 17]]\n",
      "Sensibilidade =  0.85\n",
      "Especificidade =  0.42857142857142855\n",
      "acc =  0.7407407407407407\n",
      "Cross validation (100-Fold):\n",
      "Score =  0.7417241379310344\n",
      "Std =  0.07075186497291966\n",
      "\n",
      "======================================================\n",
      "\n",
      "Modelo: Support Vector Machine\n",
      "Conjunto de Treino\n",
      "\n",
      "matriz de confusão = \n",
      " [[ 3  3]\n",
      " [ 0 28]]\n",
      "Sensibilidade =  1.0\n",
      "Especificidade =  0.5\n",
      "acc =  0.9117647058823529\n",
      "\n",
      "Conjunto de Validação\n",
      "\n",
      "matriz de confusão = \n",
      " [[ 0  7]\n",
      " [ 0 19]]\n",
      "Sensibilidade =  1.0\n",
      "Especificidade =  0.0\n",
      "acc =  0.7307692307692307\n",
      "\n",
      "Conjunto de Teste\n",
      "\n",
      "matriz de confusão = \n",
      " [[ 0  7]\n",
      " [ 0 20]]\n",
      "Sensibilidade =  1.0\n",
      "Especificidade =  0.0\n",
      "acc =  0.7407407407407407\n",
      "Cross validation (100-Fold):\n",
      "Score =  0.7572413793103447\n",
      "Std =  0.07031777708430834\n",
      "\n",
      "======================================================\n",
      "\n",
      "Modelo: Random Forests\n",
      "Conjunto de Treino\n",
      "\n",
      "matriz de confusão = \n",
      " [[ 6  0]\n",
      " [ 0 28]]\n",
      "Sensibilidade =  1.0\n",
      "Especificidade =  1.0\n",
      "acc =  1.0\n",
      "\n",
      "Conjunto de Validação\n",
      "\n",
      "matriz de confusão = \n",
      " [[ 0  7]\n",
      " [ 0 19]]\n",
      "Sensibilidade =  1.0\n",
      "Especificidade =  0.0\n",
      "acc =  0.7307692307692307\n",
      "\n",
      "Conjunto de Teste\n",
      "\n",
      "matriz de confusão = \n",
      " [[ 0  7]\n",
      " [ 0 20]]\n",
      "Sensibilidade =  1.0\n",
      "Especificidade =  0.0\n",
      "acc =  0.7407407407407407\n",
      "Cross validation (100-Fold):\n",
      "Score =  0.749655172413793\n",
      "Std =  0.07485538971776086\n"
     ]
    }
   ],
   "source": [
    "showResults(clfAlsLR, 'Logistic Regression', x, y, xTrain, xVal, xTest, yTrain, yVal, yTest)\n",
    "print('\\n======================================================\\n')\n",
    "showResults(clfAlsSVM, 'Support Vector Machine', x, y, xTrain, xVal, xTest, yTrain, yVal, yTest)\n",
    "print('\\n======================================================\\n')\n",
    "showResults(clfAlsRF, 'Random Forests', x, y, xTrain, xVal, xTest, yTrain, yVal, yTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "802c4fda",
   "metadata": {},
   "source": [
    "#### Dados: Apenas T1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "563f01c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Dimensions:  (91, 173)\n",
      "Post zeroVar:  (91, 29)\n"
     ]
    }
   ],
   "source": [
    "filteredData = t1Data\n",
    "\n",
    "x, y, xTrain, yTrain, xVal, yVal, xTest, yTest = prepareData(filteredData, 'als', 0.1)\n",
    "\n",
    "clfAlsLR = make_pipeline(StandardScaler(), LogisticRegression(penalty='l2', max_iter = 5000))\n",
    "clfAlsSVM = make_pipeline(StandardScaler(), svm.SVC(gamma='auto', kernel='rbf'))\n",
    "clfAlsRF = make_pipeline(StandardScaler(), RandomForestClassifier())\n",
    "\n",
    "clfAlsLR.fit(xTrain, yTrain);\n",
    "clfAlsSVM.fit(xTrain, yTrain);\n",
    "clfAlsRF.fit(xTrain, yTrain);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c4164e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo: Logistic Regression\n",
      "Conjunto de Treino\n",
      "\n",
      "matriz de confusão = \n",
      " [[ 4  2]\n",
      " [ 0 30]]\n",
      "Sensibilidade =  1.0\n",
      "Especificidade =  0.6666666666666666\n",
      "acc =  0.9444444444444444\n",
      "\n",
      "Conjunto de Validação\n",
      "\n",
      "matriz de confusão = \n",
      " [[ 2  9]\n",
      " [ 1 15]]\n",
      "Sensibilidade =  0.9375\n",
      "Especificidade =  0.18181818181818182\n",
      "acc =  0.6296296296296297\n",
      "\n",
      "Conjunto de Teste\n",
      "\n",
      "matriz de confusão = \n",
      " [[ 1  3]\n",
      " [ 4 20]]\n",
      "Sensibilidade =  0.8333333333333334\n",
      "Especificidade =  0.25\n",
      "acc =  0.75\n",
      "Cross validation (100-Fold):\n",
      "Score =  0.7135483870967744\n",
      "Std =  0.06488282883496582\n",
      "\n",
      "======================================================\n",
      "\n",
      "Modelo: Support Vector Machine\n",
      "Conjunto de Treino\n",
      "\n",
      "matriz de confusão = \n",
      " [[ 0  6]\n",
      " [ 0 30]]\n",
      "Sensibilidade =  1.0\n",
      "Especificidade =  0.0\n",
      "acc =  0.8333333333333334\n",
      "\n",
      "Conjunto de Validação\n",
      "\n",
      "matriz de confusão = \n",
      " [[ 0 11]\n",
      " [ 0 16]]\n",
      "Sensibilidade =  1.0\n",
      "Especificidade =  0.0\n",
      "acc =  0.5925925925925926\n",
      "\n",
      "Conjunto de Teste\n",
      "\n",
      "matriz de confusão = \n",
      " [[ 0  4]\n",
      " [ 0 24]]\n",
      "Sensibilidade =  1.0\n",
      "Especificidade =  0.0\n",
      "acc =  0.8571428571428571\n",
      "Cross validation (100-Fold):\n",
      "Score =  0.765483870967742\n",
      "Std =  0.05839600716183743\n",
      "\n",
      "======================================================\n",
      "\n",
      "Modelo: Random Forests\n",
      "Conjunto de Treino\n",
      "\n",
      "matriz de confusão = \n",
      " [[ 6  0]\n",
      " [ 0 30]]\n",
      "Sensibilidade =  1.0\n",
      "Especificidade =  1.0\n",
      "acc =  1.0\n",
      "\n",
      "Conjunto de Validação\n",
      "\n",
      "matriz de confusão = \n",
      " [[ 1 10]\n",
      " [ 0 16]]\n",
      "Sensibilidade =  1.0\n",
      "Especificidade =  0.09090909090909091\n",
      "acc =  0.6296296296296297\n",
      "\n",
      "Conjunto de Teste\n",
      "\n",
      "matriz de confusão = \n",
      " [[ 1  3]\n",
      " [ 0 24]]\n",
      "Sensibilidade =  1.0\n",
      "Especificidade =  0.25\n",
      "acc =  0.8928571428571429\n",
      "Cross validation (100-Fold):\n",
      "Score =  0.7535483870967742\n",
      "Std =  0.051918450422530855\n"
     ]
    }
   ],
   "source": [
    "showResults(clfAlsLR, 'Logistic Regression', x, y, xTrain, xVal, xTest, yTrain, yVal, yTest)\n",
    "print('\\n======================================================\\n')\n",
    "showResults(clfAlsSVM, 'Support Vector Machine', x, y, xTrain, xVal, xTest, yTrain, yVal, yTest)\n",
    "print('\\n======================================================\\n')\n",
    "showResults(clfAlsRF, 'Random Forests', x, y, xTrain, xVal, xTest, yTrain, yVal, yTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f077c67",
   "metadata": {},
   "source": [
    "#### Dados: DTI e T1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "12f9fe33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Dimensions:  (87, 959)\n",
      "Post zeroVar:  (87, 187)\n"
     ]
    }
   ],
   "source": [
    "filteredData = allData\n",
    "\n",
    "x, y, xTrain, yTrain, xVal, yVal, xTest, yTest = prepareData(filteredData, 'als', 0.1)\n",
    "\n",
    "clfAlsLR = make_pipeline(StandardScaler(), LogisticRegression(penalty='l2', max_iter = 5000))\n",
    "clfAlsSVM = make_pipeline(StandardScaler(), svm.SVC(gamma='auto', kernel='rbf'))\n",
    "clfAlsRF = make_pipeline(StandardScaler(), RandomForestClassifier())\n",
    "\n",
    "clfAlsLR.fit(xTrain, yTrain);\n",
    "clfAlsSVM.fit(xTrain, yTrain);\n",
    "clfAlsRF.fit(xTrain, yTrain);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "02ad60c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo: Logistic Regression\n",
      "Conjunto de Treino\n",
      "\n",
      "matriz de confusão = \n",
      " [[ 6  0]\n",
      " [ 0 28]]\n",
      "Sensibilidade =  1.0\n",
      "Especificidade =  1.0\n",
      "acc =  1.0\n",
      "\n",
      "Conjunto de Validação\n",
      "\n",
      "matriz de confusão = \n",
      " [[ 3  4]\n",
      " [ 0 19]]\n",
      "Sensibilidade =  1.0\n",
      "Especificidade =  0.42857142857142855\n",
      "acc =  0.8461538461538461\n",
      "\n",
      "Conjunto de Teste\n",
      "\n",
      "matriz de confusão = \n",
      " [[ 2  5]\n",
      " [ 1 19]]\n",
      "Sensibilidade =  0.95\n",
      "Especificidade =  0.2857142857142857\n",
      "acc =  0.7777777777777778\n",
      "Cross validation (100-Fold):\n",
      "Score =  0.840344827586207\n",
      "Std =  0.0638918155194279\n",
      "\n",
      "======================================================\n",
      "\n",
      "Modelo: Support Vector Machine\n",
      "Conjunto de Treino\n",
      "\n",
      "matriz de confusão = \n",
      " [[ 4  2]\n",
      " [ 0 28]]\n",
      "Sensibilidade =  1.0\n",
      "Especificidade =  0.6666666666666666\n",
      "acc =  0.9411764705882353\n",
      "\n",
      "Conjunto de Validação\n",
      "\n",
      "matriz de confusão = \n",
      " [[ 0  7]\n",
      " [ 0 19]]\n",
      "Sensibilidade =  1.0\n",
      "Especificidade =  0.0\n",
      "acc =  0.7307692307692307\n",
      "\n",
      "Conjunto de Teste\n",
      "\n",
      "matriz de confusão = \n",
      " [[ 0  7]\n",
      " [ 0 20]]\n",
      "Sensibilidade =  1.0\n",
      "Especificidade =  0.0\n",
      "acc =  0.7407407407407407\n",
      "Cross validation (100-Fold):\n",
      "Score =  0.7686206896551724\n",
      "Std =  0.08047052473280443\n",
      "\n",
      "======================================================\n",
      "\n",
      "Modelo: Random Forests\n",
      "Conjunto de Treino\n",
      "\n",
      "matriz de confusão = \n",
      " [[ 6  0]\n",
      " [ 0 28]]\n",
      "Sensibilidade =  1.0\n",
      "Especificidade =  1.0\n",
      "acc =  1.0\n",
      "\n",
      "Conjunto de Validação\n",
      "\n",
      "matriz de confusão = \n",
      " [[ 1  6]\n",
      " [ 0 19]]\n",
      "Sensibilidade =  1.0\n",
      "Especificidade =  0.14285714285714285\n",
      "acc =  0.7692307692307693\n",
      "\n",
      "Conjunto de Teste\n",
      "\n",
      "matriz de confusão = \n",
      " [[ 0  7]\n",
      " [ 0 20]]\n",
      "Sensibilidade =  1.0\n",
      "Especificidade =  0.0\n",
      "acc =  0.7407407407407407\n",
      "Cross validation (100-Fold):\n",
      "Score =  0.7924137931034481\n",
      "Std =  0.08558117743426111\n"
     ]
    }
   ],
   "source": [
    "showResults(clfAlsLR, 'Logistic Regression', x, y, xTrain, xVal, xTest, yTrain, yVal, yTest)\n",
    "print('\\n======================================================\\n')\n",
    "showResults(clfAlsSVM, 'Support Vector Machine', x, y, xTrain, xVal, xTest, yTrain, yVal, yTest)\n",
    "print('\\n======================================================\\n')\n",
    "showResults(clfAlsRF, 'Random Forests', x, y, xTrain, xVal, xTest, yTrain, yVal, yTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5637bd67",
   "metadata": {},
   "source": [
    "### Classificador: Esporadico/C9o/VAPB\n",
    "#### Dados:  Apenas DTI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae6f83fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Dimensions:  (67, 785)\n",
      "Post zeroVar:  (67, 157)\n"
     ]
    }
   ],
   "source": [
    "filteredData = dtiData[dtiData['als'] == 1]\n",
    "x, y, xTrain, yTrain, xVal, yVal, xTest, yTest = prepareData(filteredData, 'group', 0.1)\n",
    "\n",
    "clfGroupSVM = make_pipeline(StandardScaler(), svm.SVC(gamma='auto', kernel='rbf'))\n",
    "clfGroupRF = make_pipeline(StandardScaler(), RandomForestClassifier())\n",
    "\n",
    "clfGroupSVM.fit(xTrain, yTrain);\n",
    "clfGroupRF.fit(xTrain, yTrain);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0218f445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo: Support Vector Machine\n",
      "Conjunto de Treino\n",
      "\n",
      "matriz de confusão = \n",
      " [[11  0  0]\n",
      " [ 0  5  0]\n",
      " [ 0  0 10]]\n",
      "Sensibilidade =  0.45454545454545453\n",
      "Especificidade =  inf\n",
      "acc =  1.0\n",
      "\n",
      "Conjunto de Validação\n",
      "\n",
      "matriz de confusão = \n",
      " [[5 0 2]\n",
      " [2 0 2]\n",
      " [7 0 2]]\n",
      "Sensibilidade =  0.0\n",
      "Especificidade =  inf\n",
      "acc =  0.35\n",
      "\n",
      "Conjunto de Teste\n",
      "\n",
      "matriz de confusão = \n",
      " [[9 0 2]\n",
      " [1 1 1]\n",
      " [4 0 3]]\n",
      "Sensibilidade =  0.09090909090909091\n",
      "Especificidade =  inf\n",
      "acc =  0.6190476190476191\n",
      "Cross validation (100-Fold):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-34c0cbb77335>:8: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  Spec = CM[0,0]/(y == 0).sum() # Calculate Specificity\n",
      "<ipython-input-15-34c0cbb77335>:8: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  Spec = CM[0,0]/(y == 0).sum() # Calculate Specificity\n",
      "<ipython-input-15-34c0cbb77335>:8: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  Spec = CM[0,0]/(y == 0).sum() # Calculate Specificity\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score =  0.497391304347826\n",
      "Std =  0.08482607581396312\n",
      "\n",
      "======================================================\n",
      "\n",
      "Modelo: Random Forests\n",
      "Conjunto de Treino\n",
      "\n",
      "matriz de confusão = \n",
      " [[11  0  0]\n",
      " [ 0  5  0]\n",
      " [ 0  0 10]]\n",
      "Sensibilidade =  0.45454545454545453\n",
      "Especificidade =  inf\n",
      "acc =  1.0\n",
      "\n",
      "Conjunto de Validação\n",
      "\n",
      "matriz de confusão = \n",
      " [[5 1 1]\n",
      " [2 0 2]\n",
      " [5 0 4]]\n",
      "Sensibilidade =  0.0\n",
      "Especificidade =  inf\n",
      "acc =  0.45\n",
      "\n",
      "Conjunto de Teste\n",
      "\n",
      "matriz de confusão = \n",
      " [[8 1 2]\n",
      " [1 1 1]\n",
      " [3 1 3]]\n",
      "Sensibilidade =  0.09090909090909091\n",
      "Especificidade =  inf\n",
      "acc =  0.5714285714285714\n",
      "Cross validation (100-Fold):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-34c0cbb77335>:8: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  Spec = CM[0,0]/(y == 0).sum() # Calculate Specificity\n",
      "<ipython-input-15-34c0cbb77335>:8: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  Spec = CM[0,0]/(y == 0).sum() # Calculate Specificity\n",
      "<ipython-input-15-34c0cbb77335>:8: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  Spec = CM[0,0]/(y == 0).sum() # Calculate Specificity\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score =  0.508695652173913\n",
      "Std =  0.08531050813195036\n"
     ]
    }
   ],
   "source": [
    "showResults(clfGroupSVM, 'Support Vector Machine', x, y, xTrain, xVal, xTest, yTrain, yVal, yTest)\n",
    "print('\\n======================================================\\n')\n",
    "showResults(clfGroupRF, 'Random Forests', x, y, xTrain, xVal, xTest, yTrain, yVal, yTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "034b48c0",
   "metadata": {},
   "source": [
    "#### Dados:  Apenas T1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e323836e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Dimensions:  (70, 173)\n",
      "Post zeroVar:  (70, 28)\n"
     ]
    }
   ],
   "source": [
    "filteredData = t1Data[t1Data['als'] == 1]\n",
    "x, y, xTrain, yTrain, xVal, yVal, xTest, yTest = prepareData(filteredData, 'group', 0.1)\n",
    "\n",
    "clfGroupSVM = make_pipeline(StandardScaler(), svm.SVC(gamma='auto', kernel='rbf'))\n",
    "clfGroupRF = make_pipeline(StandardScaler(), RandomForestClassifier())\n",
    "\n",
    "clfGroupSVM.fit(xTrain, yTrain);\n",
    "clfGroupRF.fit(xTrain, yTrain);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b2a34077",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo: Support Vector Machine\n",
      "Conjunto de Treino\n",
      "\n",
      "matriz de confusão = \n",
      " [[11  0  0]\n",
      " [ 0  7  0]\n",
      " [ 1  0  9]]\n",
      "Sensibilidade =  0.6363636363636364\n",
      "Especificidade =  inf\n",
      "acc =  0.9642857142857143\n",
      "\n",
      "Conjunto de Validação\n",
      "\n",
      "matriz de confusão = \n",
      " [[7 0 0]\n",
      " [3 0 1]\n",
      " [8 2 0]]\n",
      "Sensibilidade =  0.0\n",
      "Especificidade =  inf\n",
      "acc =  0.3333333333333333\n",
      "\n",
      "Conjunto de Teste\n",
      "\n",
      "matriz de confusão = \n",
      " [[7 4 1]\n",
      " [0 3 0]\n",
      " [4 0 2]]\n",
      "Sensibilidade =  0.25\n",
      "Especificidade =  inf\n",
      "acc =  0.5714285714285714\n",
      "Cross validation (100-Fold):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-34c0cbb77335>:8: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  Spec = CM[0,0]/(y == 0).sum() # Calculate Specificity\n",
      "<ipython-input-15-34c0cbb77335>:8: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  Spec = CM[0,0]/(y == 0).sum() # Calculate Specificity\n",
      "<ipython-input-15-34c0cbb77335>:8: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  Spec = CM[0,0]/(y == 0).sum() # Calculate Specificity\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score =  0.4875\n",
      "Std =  0.09973924336321519\n",
      "\n",
      "======================================================\n",
      "\n",
      "Modelo: Random Forests\n",
      "Conjunto de Treino\n",
      "\n",
      "matriz de confusão = \n",
      " [[11  0  0]\n",
      " [ 0  7  0]\n",
      " [ 0  0 10]]\n",
      "Sensibilidade =  0.6363636363636364\n",
      "Especificidade =  inf\n",
      "acc =  1.0\n",
      "\n",
      "Conjunto de Validação\n",
      "\n",
      "matriz de confusão = \n",
      " [[5 0 2]\n",
      " [1 0 3]\n",
      " [6 2 2]]\n",
      "Sensibilidade =  0.0\n",
      "Especificidade =  inf\n",
      "acc =  0.3333333333333333\n",
      "\n",
      "Conjunto de Teste\n",
      "\n",
      "matriz de confusão = \n",
      " [[7 3 2]\n",
      " [1 2 0]\n",
      " [5 0 1]]\n",
      "Sensibilidade =  0.16666666666666666\n",
      "Especificidade =  inf\n",
      "acc =  0.47619047619047616\n",
      "Cross validation (100-Fold):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-34c0cbb77335>:8: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  Spec = CM[0,0]/(y == 0).sum() # Calculate Specificity\n",
      "<ipython-input-15-34c0cbb77335>:8: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  Spec = CM[0,0]/(y == 0).sum() # Calculate Specificity\n",
      "<ipython-input-15-34c0cbb77335>:8: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  Spec = CM[0,0]/(y == 0).sum() # Calculate Specificity\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score =  0.46791666666666665\n",
      "Std =  0.10169654615570776\n"
     ]
    }
   ],
   "source": [
    "showResults(clfGroupSVM, 'Support Vector Machine', x, y, xTrain, xVal, xTest, yTrain, yVal, yTest)\n",
    "print('\\n======================================================\\n')\n",
    "showResults(clfGroupRF, 'Random Forests', x, y, xTrain, xVal, xTest, yTrain, yVal, yTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3dc251e",
   "metadata": {},
   "source": [
    "#### Dados:  DTI e T1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3faf8083",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Dimensions:  (67, 959)\n",
      "Post zeroVar:  (67, 186)\n"
     ]
    }
   ],
   "source": [
    "filteredData = allData[allData['als'] == 1]\n",
    "x, y, xTrain, yTrain, xVal, yVal, xTest, yTest = prepareData(filteredData, 'group', 0.1)\n",
    "\n",
    "clfGroupSVM = make_pipeline(StandardScaler(), svm.SVC(gamma='auto', kernel='rbf'))\n",
    "clfGroupRF = make_pipeline(StandardScaler(), RandomForestClassifier())\n",
    "\n",
    "clfGroupSVM.fit(xTrain, yTrain);\n",
    "clfGroupRF.fit(xTrain, yTrain);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4f3f0d06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Modelo: Support Vector Machine\n",
      "Conjunto de Treino\n",
      "\n",
      "matriz de confusão = \n",
      " [[11  0  0]\n",
      " [ 0  5  0]\n",
      " [ 0  0 10]]\n",
      "Sensibilidade =  0.45454545454545453\n",
      "Especificidade =  inf\n",
      "acc =  1.0\n",
      "\n",
      "Conjunto de Validação\n",
      "\n",
      "matriz de confusão = \n",
      " [[6 1 0]\n",
      " [2 0 2]\n",
      " [7 0 2]]\n",
      "Sensibilidade =  0.0\n",
      "Especificidade =  inf\n",
      "acc =  0.4\n",
      "\n",
      "Conjunto de Teste\n",
      "\n",
      "matriz de confusão = \n",
      " [[8 1 2]\n",
      " [1 2 0]\n",
      " [4 0 3]]\n",
      "Sensibilidade =  0.18181818181818182\n",
      "Especificidade =  inf\n",
      "acc =  0.6190476190476191\n",
      "Cross validation (100-Fold):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-34c0cbb77335>:8: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  Spec = CM[0,0]/(y == 0).sum() # Calculate Specificity\n",
      "<ipython-input-15-34c0cbb77335>:8: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  Spec = CM[0,0]/(y == 0).sum() # Calculate Specificity\n",
      "<ipython-input-15-34c0cbb77335>:8: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  Spec = CM[0,0]/(y == 0).sum() # Calculate Specificity\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score =  0.5182608695652173\n",
      "Std =  0.08445980912409098\n",
      "\n",
      "======================================================\n",
      "\n",
      "Modelo: Random Forests\n",
      "Conjunto de Treino\n",
      "\n",
      "matriz de confusão = \n",
      " [[11  0  0]\n",
      " [ 0  5  0]\n",
      " [ 0  0 10]]\n",
      "Sensibilidade =  0.45454545454545453\n",
      "Especificidade =  inf\n",
      "acc =  1.0\n",
      "\n",
      "Conjunto de Validação\n",
      "\n",
      "matriz de confusão = \n",
      " [[5 1 1]\n",
      " [2 0 2]\n",
      " [2 0 7]]\n",
      "Sensibilidade =  0.0\n",
      "Especificidade =  inf\n",
      "acc =  0.6\n",
      "\n",
      "Conjunto de Teste\n",
      "\n",
      "matriz de confusão = \n",
      " [[9 2 0]\n",
      " [1 2 0]\n",
      " [1 0 6]]\n",
      "Sensibilidade =  0.18181818181818182\n",
      "Especificidade =  inf\n",
      "acc =  0.8095238095238095\n",
      "Cross validation (100-Fold):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-15-34c0cbb77335>:8: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  Spec = CM[0,0]/(y == 0).sum() # Calculate Specificity\n",
      "<ipython-input-15-34c0cbb77335>:8: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  Spec = CM[0,0]/(y == 0).sum() # Calculate Specificity\n",
      "<ipython-input-15-34c0cbb77335>:8: RuntimeWarning: divide by zero encountered in long_scalars\n",
      "  Spec = CM[0,0]/(y == 0).sum() # Calculate Specificity\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score =  0.6895652173913044\n",
      "Std =  0.09990922155629518\n"
     ]
    }
   ],
   "source": [
    "showResults(clfGroupSVM, 'Support Vector Machine', x, y, xTrain, xVal, xTest, yTrain, yVal, yTest)\n",
    "print('\\n======================================================\\n')\n",
    "showResults(clfGroupRF, 'Random Forests', x, y, xTrain, xVal, xTest, yTrain, yVal, yTest)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e6c4cb9",
   "metadata": {},
   "source": [
    "## Exportar Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c8449b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interim\n",
    "faData.to_csv('../data/interim/faData.csv', index=False)\n",
    "l1Data.to_csv('../data/interim/l1Data.csv', index=False)\n",
    "l2Data.to_csv('../data/interim/l2Data.csv', index=False)\n",
    "l3Data.to_csv('../data/interim/l3Data.csv', index=False)\n",
    "vlData.to_csv('../data/interim/vlData.csv', index=False)\n",
    "\n",
    "# Processed\n",
    "allData.to_csv('../data/processed/processedData.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
